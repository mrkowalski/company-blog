---
date: '2026-01-17T15:23:36+01:00'
draft: true
title: 'In the post AI world, your employees need mental models'
tags:
  - ai
  - recruitment
---

Knowledge is becoming commodity. Most of it is just a prompt away. So, when hiring or training employees, which skills are defensible and stand the test of AI?

The three key differentiating factors of your employees vs AI are:

- Insider info.
- Soft skills.
- Mental models they know and apply.

Let's break them down.

### Insider info

This is all your people know about the business, clients and processes. Many of these things are likely not documented anywhere and LLMs have no way to know. Having said that, some industry insights are (increasingly) accessible. Books, websites, blog posts and social networks, like [Reddit](https://www.reddit.com/) contain valuable information. Not everything your employees know, but still. This may also be your employees discuss proprietary topics with AI chats at home and LLMs learn.

### Soft skills

It is ability to understand others, make sense of their feeligs, their body languages, moods, preferences and best mates. Some people are great at navigating this space and have ability to deliberately and positively influence own and others' performance via relationship building. This is not accessible to LLMs at all, because they are not present in the environment to be able to see. One may argue that emails and chats give access, but it is out of context, stripped of non-verbal communication, moods, health and surroundings.

### Mental models

"An internal representation of external reality".[^1] This is what people use to guide their cause-and-effect understanding and decision making. To name few:

- Being aware of cognitive biases and their mechanics. Example: anchoring.
- Normal distribution and its applications.
- Ability to understand human behavior and motivations.
- Game theory

This is the toughest one to crack for AI, because AI has no means to apply it. The required features are just not there; AI can't distinguish imagination from reality and has very rudimentary ability to reason. Regardless of what marketing teams of model vendors tell you, AI reasoning is currently algorithmic ("hardcoded"), lacking human flexibility and independence. Existing methods are brittle and time consuming (i.e. "chain of thought"). We are able to <u>simulate</u> executive functions with reinforcement learning but we fail to make AI reason autonomously. And on top of these unreliable methods, AI has now way to experience reality; it mostly only read about it.

### So what?

Lack of autonomy mixed with unpredictability makes your AI reckless or idle. It does not know when to reason and why. Without this skill, mental models are indistinguishable and vague. Why would AI use them? How would it choose between them?

For us, mental models are transferable knowledge that enables us to reason and organize knowledge. They allow us to make sound decisions based on *insider info*, *relationships*, experience and common knowledge. Interestingly, mental models do not make much sense as a theory. It takes time and practice to learn to apply them.

Because of all the above, if there is one skill to bet on in the age of AI, I bet on mental models. Hiring them and teaching them is my secret team productivity booster.

### Breakdown for reference

| Skill         | Transferable? | Accessible to AI? | Is AI able to learn it? |
| --------------| ------------- | ----------------- | ----------------------- |
| Insider info  | No            | Partly            | Yes                     |
| Soft skills   | Yes           | No                | Yes                     |
| Mental models | Yes           | Yes               | No                      |

[^1]: [Mental Model, Wikipedia](https://en.wikipedia.org/wiki/Mental_model)
