---
date: '2026-01-17T15:23:36+01:00'
draft: true
title: 'In the post AI world, your employees need mental models'
tags:
  - ai
  - recruitment
---

Knowledge is becoming commodity. Lot of it is just a prompt away. So, when hiring or training employees, what knowledge is defensible and stands the test of AI?

The key three differentiating factors of your employees vs AI are:

- Insider knowledge.
- Relationships.
- Mental models they know and apply.

Let's break them down:

### Insider knowledge

This is all your people know about the business, clients and processes. Many of these things are likely not documented anywhere and LLMs have no way to know. Having said that, some industry insights are (increasingly) accessible. Books, websites, blog posts and social networks, like [Reddit](https://www.reddit.com/) contain valuable information. Not everything your employees know, but still. This may also be, that your employees discuss proprietary topics with AI chats at home and LLMs learn.

### Relationships

It is what people know about each other, how they feel, their body languages, moods, preferences and best mates. Some people are great at navigating this space and have ability to deliberately and positively influence own and others' performance via relationship building. "Soft skills", vaguely put. This is not accessible to LLMs at all, because they are not present in the environment to be able to see. One may argue that emails and chats give access, but it is out of context, stripped of non-verbal communication and surroundings.

### Mental models

"An internal representation of external reality".[^1] This is what people use to guide their cause-and-effect understanding and decision making. To name few:

- Being aware of cognitive biases and their mechanics. Like anchoring.
- Normal distribution and its application.
- Ability to understand human behavior and motivations.
- Game theory

This is the toughest one to crack for AI, because even if AI knew it (and it sure does), it has no way to apply it. The required features are just not there; AI can't distinguish imagination from reality and has very rudimentary ability to reason. Regardless of what marketing teams of model vendors tell you, AI reasoning is, compared to human, at the level of 80's pocket calculator. Existing methods are brittle and time consuming (i.e. "chain of thought"). We were able to <u>simulate</u> executive functions with reinforcement learning but we fail to make AI reason autonomously. And on top of these unreliable methods, AI has now way to experience our reality. It can only read about it.

### So what?

Mental models.

[^1]: [Mental Model, Wikipedia](https://en.wikipedia.org/wiki/Mental_model)
